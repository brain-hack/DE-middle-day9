{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스트리밍 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word count 예제 \n",
    "9999 소켓을 통해 들어오는 메시지를 워드카운팅하는 코드입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트리밍 처리를 위한 쓰레드 두개를 생성합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[2]\", \"NetworkWordCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 간격을 1초로 맞추어 스트리밍 컨텍스트 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트리밍 데이터를 받을 소켓을 엽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄워쓰기를 기준으로 텍스트 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 배치별 워드카운팅을 진행할 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stateful streaming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 코드는 각 배치마다 따로 결과를 냈지만 이번에는 누산을 해보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[2]\", \"StatefulNetworkWordCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장애 시, 복구시점 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "updatebykey의 타겟이 되는 함수 \n",
    "기존의 것과 새로운 것이 합쳐집니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFunc(new_values, last_sum):\n",
    " \treturn sum(new_values) + (last_sum or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "\t\t\t\t\t.map(lambda word: (word, 1))\\\n",
    "                    .updateStateByKey(updateFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_counts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structed streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark2.0에서는 dataframe을 이용한 스트리밍 처리를 지원합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 스트리밍 컨텍스트를 만들지 않습니다. 그 이유는 이미 스팤 세션에 들어있기 때문이죠 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e932d5bd8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"StructuredNetworkWordCount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark.conf.set(\"spark.driver.memory\", \"16g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark\\\n",
    "\t.readStream\\\n",
    "\t.format('socket')\\\n",
    "\t.option('host', 'localhost')\\\n",
    "\t.option('port', 9999)\\\n",
    "\t.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explode : arrray의 각 구성요소를 쪼개서 행으로 만듬(groupby를 가능하게 만듬)<br>\n",
    "spllit : string을 조건에 맞게 쪼개서 array로 만듬\n",
    "\n",
    "RDD에서의 lines.flatMap(lambda line: line.split(\" \"))와 동일한 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.select(\n",
    "\texplode(\n",
    "    \tsplit(lines.value, ' ')\n",
    "\t).alias('word')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word컬럼을 같은 것끼리 묶은 후 카운팅을 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate running word count\n",
    "wordCounts = words.groupBy('word').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = wordCounts\\\n",
    "\t.writeStream\\\n",
    "\t.outputMode('complete')\\\n",
    "\t.format('console')\\\n",
    "\t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미션 : 카프키를 이용해서 스트림 처리하기\n",
    "\n",
    "sparkin 토픽으로 스트림을 받아와서  <br>\n",
    "sparkout 토픽으로 처리 결과를 내보내는 코드 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카프카로 읽어오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"subscribe\", \"topic1\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 멀티토픽도 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"subscribe\", \"topic1,topic2\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토픽목록에 패턴도 걸 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"subscribePattern\", \"topic.*\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오프셋 지정도 가능합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"subscribePattern\", \"topic.*\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"endingOffsets\", \"latest\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카프카로 싱크하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df \\\n",
    "  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "  .writeStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"topic\", \"topic1\") \\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네 멀티토픽 가능하구요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df \\\n",
    "  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "  .writeStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\") \\\n",
    "  .option(\"topic\", \"topic1,topic2\") \\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLlib는 머리 가슴 배로 나뉘어 집니다 <br>\n",
    "- 머리 : 전처리 - 우리가 배웠던 na처리 아웃라이어 처리 등을 하면서 데이터 클렌징/클리닝을 하고 ml 모델이 처리하기 쉬운형태로 transformation\n",
    "- 가슴 : ML알고리즘 - ML 모델을 이용해서 classfication, clustering, regression 등으로 문제를 해결합니다 \n",
    "- 배 : 유틸리티 - 기술통계, 카이 스퀘어 테스트(정확도 테스트) 시각화 등등 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사례 1 : 유아 생존율을 예측해봅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark.conf.set(\"spark.driver.memory\", \"16g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "\n",
    "## 데이터 스키마 지정\n",
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
    "    ('BIRTH_YEAR', typ.IntegerType()),\n",
    "    ('BIRTH_MONTH', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
    "    ('MOTHER_EDUCATION', typ.StringType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('FATHER_EDUCATION', typ.StringType()),\n",
    "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.StringType()),\n",
    "    ('DIABETES_GEST', typ.StringType()),\n",
    "    ('HYP_TENS_PRE', typ.StringType()),\n",
    "    ('HYP_TENS_GEST', typ.StringType()),\n",
    "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
    "    ('NO_RISK', typ.StringType()),\n",
    "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
    "    ('LABOR_IND', typ.StringType()),\n",
    "    ('LABOR_AUGM', typ.StringType()),\n",
    "    ('STEROIDS', typ.StringType()),\n",
    "    ('ANTIBIOTICS', typ.StringType()),\n",
    "    ('ANESTHESIA', typ.StringType()),\n",
    "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
    "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
    "    ('APGAR_5', typ.IntegerType()),\n",
    "    ('APGAR_5_RECODE', typ.StringType()),\n",
    "    ('APGAR_10', typ.IntegerType()),\n",
    "    ('APGAR_10_RECODE', typ.StringType()),\n",
    "    ('INFANT_SEX', typ.StringType()),\n",
    "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
    "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
    "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
    "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
    "    ('INFANT_SURFACANT', typ.StringType()),\n",
    "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
    "    ('INFANT_SEIZURES', typ.StringType()),\n",
    "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
    "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
    "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
    "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
    "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
    "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
    "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
    "    ('INFANT_BREASTFED', typ.StringType())\n",
    "]\n",
    "\n",
    "schema = typ.StructType([\n",
    "        typ.StructField(e[0], e[1], False) for e in labels\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"sparkML\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark.conf.set(\"spark.driver.memory\", \"16g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv('births_train.csv.gz', \n",
    "                        header=True, \n",
    "                        schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레코드 딕셔너리 명시\n",
    "Y -> 1 , N -> 0 , U -> 0으로 바꿀 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_dictionary = {\n",
    "    'YNU': {\n",
    "        'Y': 1,\n",
    "        'N': 0,\n",
    "        'U': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫번째 목표는 INFANT_ALIVE_AT_REPORT가 1인지 0인지 예측할겁니다. \n",
    "#### 이것과 관련이 있는 피처들은 빠지고 오로지 어머니 아버지 출생지와 관련된 피처만 가지고 예측하고자 합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_BEFORE', \n",
    "    'CIG_1_TRI', \n",
    "    'CIG_2_TRI', \n",
    "    'CIG_3_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'MOTHER_DELIVERY_WEIGHT', \n",
    "    'MOTHER_WEIGHT_GAIN', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]\n",
    "\n",
    "births_trimmed = births.select(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레코드 함수 정의 \n",
    "- 아까 만들어뒀던 레코드 딕셔너리가 여기 쓰입니다. 딕셔너리에 따라 변환 \n",
    "- correct_cig는 99가 아닐때는 자기 값을 그대로 들고가고 99일때만 0으로 바뀝니다. \n",
    "- 이걸 데이터프레임에 직접쓰면 좋겠지만 스파크가 이 명령을 알아먹을 수 있는 UDF형태로 변환이 필요합니다. 그래서 UDF 변환이 가능한 rec_integer함수를 만들었습니다(레코드 함수 전달, 타입 명시 -> 여기선 정수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "def recode(col, key):        \n",
    "    return recode_dictionary[key][col] \n",
    "\n",
    "def correct_cig(feat):\n",
    "    return func \\\n",
    "        .when(func.col(feat) != 99, func.col(feat))\\\n",
    "        .otherwise(0)\n",
    "\n",
    "rec_integer = func.udf(recode, typ.IntegerType())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 레코드 변환 작업을 시작할겁니다. 흡연량에 관련된 피처부터 고쳐봅니다. \n",
    "withColumn은 변환할 컬럼을 첫번째 param으로 변환된 컬럼을 두번째 param으로 지정합니다. (컬럼명을 바꾸지 않앗습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_trimmed \\\n",
    "    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n",
    "    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n",
    "    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n",
    "    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 Y N U를 변형해줍니다. 그럴려면 일단 Y N U가 있는 컬럼을 알아내야 합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'N']\n",
      "['7', '3', '5', '6', '9', '1', '4', '2']\n",
      "['Y', 'U', 'N']\n",
      "['Y', 'U', 'N']\n",
      "['Y', 'U', 'N']\n",
      "['Y', 'U', 'N']\n",
      "['Y', 'U', 'N']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['INFANT_ALIVE_AT_REPORT',\n",
       " 'DIABETES_PRE',\n",
       " 'DIABETES_GEST',\n",
       " 'HYP_TENS_PRE',\n",
       " 'HYP_TENS_GEST',\n",
       " 'PREV_BIRTH_PRETERM']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n",
    "\n",
    "YNU_cols = []\n",
    "\n",
    "for i, s in enumerate(cols):\n",
    "    if s[1] == typ.StringType():\n",
    "        dis = births.select(s[0]) \\\n",
    "            .distinct() \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: row[0]) \\\n",
    "            .collect()\n",
    "\n",
    "        print(dis)\n",
    "        if 'Y' in dis:\n",
    "            YNU_cols.append(s[0])\n",
    "\n",
    "YNU_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터프레임은 피처를 고르면서 동시에 피처를 변형할 수 있습니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0),\n",
       " Row(INFANT_NICU_ADMISSION='N', INFANT_NICU_ADMISSION_RECODE=0),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select([\n",
    "        'INFANT_NICU_ADMISSION', \n",
    "        rec_integer(\n",
    "            'INFANT_NICU_ADMISSION', func.lit('YNU')\n",
    "        ) \\\n",
    "        .alias('INFANT_NICU_ADMISSION_RECODE')]\n",
    "     ).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 YNU cols를 한방에 처리하기 위해 이러한 transformation list를 민듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_YNU = [\n",
    "    rec_integer(x, func.lit('YNU')).alias(x) \n",
    "    if x in YNU_cols \n",
    "    else x \n",
    "    for x in births_transformed.columns\n",
    "]\n",
    "\n",
    "births_transformed = births_transformed.select(exprs_YNU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플로 뽑아서 제대로 바뀐지 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+-------------+------------------+\n",
      "|DIABETES_PRE|DIABETES_GEST|HYP_TENS_PRE|HYP_TENS_GEST|PREV_BIRTH_PRETERM|\n",
      "+------------+-------------+------------+-------------+------------------+\n",
      "|           0|            0|           0|            0|                 0|\n",
      "|           0|            0|           0|            0|                 0|\n",
      "|           0|            0|           0|            0|                 0|\n",
      "|           0|            0|           0|            0|                 1|\n",
      "|           0|            0|           0|            0|                 0|\n",
      "+------------+-------------+------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births_transformed.select(YNU_cols[-5:]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터에 대해 알아보기 \n",
    "- 통계적 모델을 잘 알려진 방법으로 만들기 위해 데이터를 잘 파악 \n",
    "- 데이터를 파악하지 않고도 훌륭한 모델을 만들 수 있으나 공수가 많이 필요함 \n",
    "- 80%의 데이터 전처리와 15%의 데이터 파악 (모델은 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기술통계 \n",
    "우리는 MLlib 사용이 목적이므로 모든 데이터를 가지고 통계를 내는 describe를 사용하는 것 보다 샘플을 이용해서 통계를 내는 colStats 함수를 사용해보겠습니다. (속도는 빠르나 표본집단의 신뢰도 문제 그래서 모집단이 많아야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### colstats 함수 \n",
    "MultivariateStatisticalSummary 객체 리턴  아래 이 객체가 가지고 있는 것들\n",
    "- count() row갯수\n",
    "- max() 한 column 최댓값\n",
    "- mean() 한 column 평균\n",
    "- min() 한 column 최솟값\n",
    "- normL1() 한 column의 L1 norm  절대값의 합\n",
    "- normL2() 한 column의 L2 norm  유클리드 백터 크기  루트(제곱수의 합)\n",
    "- numNonzeros() 한 column에서의 0이 아닌 갯수\n",
    "- variance() 한 column의 분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTHER_AGE_YEARS: \t28.30 \t 6.08\n",
      "FATHER_COMBINED_AGE: \t44.55 \t 27.55\n",
      "CIG_BEFORE: \t1.43 \t 5.18\n",
      "CIG_1_TRI: \t0.91 \t 3.83\n",
      "CIG_2_TRI: \t0.70 \t 3.31\n",
      "CIG_3_TRI: \t0.58 \t 3.11\n",
      "MOTHER_HEIGHT_IN: \t65.12 \t 6.45\n",
      "MOTHER_PRE_WEIGHT: \t214.50 \t 210.21\n",
      "MOTHER_DELIVERY_WEIGHT: \t223.63 \t 180.01\n",
      "MOTHER_WEIGHT_GAIN: \t30.74 \t 26.23\n"
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.stat as st\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n",
    "                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n",
    "                'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n",
    "                'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n",
    "               ]\n",
    "\n",
    "numeric_rdd = births_transformed\\\n",
    "                       .select(numeric_cols)\\\n",
    "                       .rdd \\\n",
    "                       .map(lambda row: [e for e in row])\n",
    "\n",
    "mllib_stats = st.Statistics.colStats(numeric_rdd)\n",
    "\n",
    "for col, m, v in zip(numeric_cols, \n",
    "                     mllib_stats.mean(), \n",
    "                     mllib_stats.variance()):\n",
    "    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터를 통해 알 수 있는 것\n",
    "1. 아버지의 비해 어머니 나이가 적다\n",
    "2. 어머니의 평균 나이는 28이고 아버지는 44이다\n",
    "3. 몇몇은 임신중에 금연을 하였고, 몇몇은 흡연중\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "카테고리 값(이산 값)의 빈도수를 계산해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFANT_ALIVE_AT_REPORT [(1, 23349), (0, 22080)]\n",
      "BIRTH_PLACE [('1', 44558), ('4', 327), ('3', 224), ('2', 136), ('7', 91), ('5', 74), ('6', 11), ('9', 8)]\n",
      "DIABETES_PRE [(0, 44881), (1, 548)]\n",
      "DIABETES_GEST [(0, 43451), (1, 1978)]\n",
      "HYP_TENS_PRE [(0, 44348), (1, 1081)]\n",
      "HYP_TENS_GEST [(0, 43302), (1, 2127)]\n",
      "PREV_BIRTH_PRETERM [(0, 43088), (1, 2341)]\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [e for e in births_transformed.columns \n",
    "                    if e not in numeric_cols]\n",
    "\n",
    "categorical_rdd = births_transformed\\\n",
    "                       .select(categorical_cols)\\\n",
    "                       .rdd \\\n",
    "                       .map(lambda row: [e for e in row])\n",
    "            \n",
    "for i, col in enumerate(categorical_cols):\n",
    "    agg = categorical_rdd \\\n",
    "        .groupBy(lambda row: row[i]) \\\n",
    "        .map(lambda row: (row[0], len(row[1])))\n",
    "        \n",
    "    print(col, sorted(agg.collect(), \n",
    "                      key=lambda el: el[1], \n",
    "                      reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상관계수 파악\n",
    "0.5 이상만 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIG_BEFORE-to-CIG_1_TRI: 0.83\n",
      "CIG_BEFORE-to-CIG_2_TRI: 0.72\n",
      "CIG_BEFORE-to-CIG_3_TRI: 0.62\n",
      "CIG_1_TRI-to-CIG_BEFORE: 0.83\n",
      "CIG_1_TRI-to-CIG_2_TRI: 0.87\n",
      "CIG_1_TRI-to-CIG_3_TRI: 0.76\n",
      "CIG_2_TRI-to-CIG_BEFORE: 0.72\n",
      "CIG_2_TRI-to-CIG_1_TRI: 0.87\n",
      "CIG_2_TRI-to-CIG_3_TRI: 0.89\n",
      "CIG_3_TRI-to-CIG_BEFORE: 0.62\n",
      "CIG_3_TRI-to-CIG_1_TRI: 0.76\n",
      "CIG_3_TRI-to-CIG_2_TRI: 0.89\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_DELIVERY_WEIGHT: 0.54\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.65\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_PRE_WEIGHT: 0.54\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.60\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_PRE_WEIGHT: 0.65\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_DELIVERY_WEIGHT: 0.60\n"
     ]
    }
   ],
   "source": [
    "corrs = st.Statistics.corr(numeric_rdd)\n",
    "\n",
    "for i, el in enumerate(corrs > 0.5):\n",
    "    correlated = [\n",
    "        (numeric_cols[j], corrs[i][j]) \n",
    "        for j, e in enumerate(el) \n",
    "        if e == 1.0 and j != i]\n",
    "    \n",
    "    if len(correlated) > 0:\n",
    "        for e in correlated:\n",
    "            print('{0}-to-{1}: {2:.2f}' \\\n",
    "                  .format(numeric_cols[i], e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상관계수 분석\n",
    "- CIG관련 상관계수가 매우 크므로 CIG_TRI1만 사용합니다 \n",
    "- 몸무게관련도 상관관게가 크므로 MOTHER_PRE_WEIGHT만 사용합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_1_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]\n",
    "births_transformed = births_transformed.select([e for e in features_to_keep])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계값 테스트 \n",
    "카테고리 피처는 상관계수를 구할 수 없으므로 카이-스퀘어 테스트를 합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRTH_PLACE 0.0\n",
      "DIABETES_PRE 0.0\n",
      "DIABETES_GEST 0.0\n",
      "HYP_TENS_PRE 0.0\n",
      "HYP_TENS_GEST 0.0\n",
      "PREV_BIRTH_PRETERM 0.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.linalg as ln\n",
    "\n",
    "for cat in categorical_cols[1:]:\n",
    "    agg = births_transformed \\\n",
    "        .groupby('INFANT_ALIVE_AT_REPORT') \\\n",
    "        .pivot(cat) \\\n",
    "        .count()    \n",
    "\n",
    "    agg_rdd = agg \\\n",
    "        .rdd\\\n",
    "        .map(lambda row: (row[1:])) \\\n",
    "        .flatMap(lambda row: \n",
    "                 [0 if e == None else e for e in row]) \\\n",
    "        .collect()\n",
    "\n",
    "    row_length = len(agg.collect()[0]) - 1\n",
    "    # mllib는 natrices가 들어가야 합니다\n",
    "    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n",
    "    \n",
    "    test = st.Statistics.chiSqTest(agg)\n",
    "    print(cat, round(test.pValue, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 카이스퀘어테스트 분석\n",
    "그냥 다 다르다 사용해도 무방하다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 데이터셋 만들기\n",
    "- 스트링 타입은 해싱\n",
    "- 형태를 동일하게 잡음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=29, FATHER_COMBINED_AGE=99, CIG_1_TRI=0, MOTHER_HEIGHT_IN=99, MOTHER_PRE_WEIGHT=999, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=22, FATHER_COMBINED_AGE=29, CIG_1_TRI=0, MOTHER_HEIGHT_IN=65, MOTHER_PRE_WEIGHT=180, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=38, FATHER_COMBINED_AGE=40, CIG_1_TRI=0, MOTHER_HEIGHT_IN=63, MOTHER_PRE_WEIGHT=155, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=39, FATHER_COMBINED_AGE=42, CIG_1_TRI=0, MOTHER_HEIGHT_IN=60, MOTHER_PRE_WEIGHT=128, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=1), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=18, FATHER_COMBINED_AGE=99, CIG_1_TRI=4, MOTHER_HEIGHT_IN=61, MOTHER_PRE_WEIGHT=110, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=32, FATHER_COMBINED_AGE=37, CIG_1_TRI=0, MOTHER_HEIGHT_IN=66, MOTHER_PRE_WEIGHT=150, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=22, FATHER_COMBINED_AGE=25, CIG_1_TRI=0, MOTHER_HEIGHT_IN=68, MOTHER_PRE_WEIGHT=155, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=25, FATHER_COMBINED_AGE=26, CIG_1_TRI=0, MOTHER_HEIGHT_IN=64, MOTHER_PRE_WEIGHT=136, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=26, FATHER_COMBINED_AGE=32, CIG_1_TRI=0, MOTHER_HEIGHT_IN=64, MOTHER_PRE_WEIGHT=140, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0), Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=39, FATHER_COMBINED_AGE=66, CIG_1_TRI=0, MOTHER_HEIGHT_IN=65, MOTHER_PRE_WEIGHT=140, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,29.0,99.0,0.0,99.0,999.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,22.0,29.0,0.0,65.0,180.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,38.0,40.0,0.0,63.0,155.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,39.0,42.0,0.0,60.0,128.0,0.0,0.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,18.0,99.0,4.0,61.0,110.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,32.0,37.0,0.0,66.0,150.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,22.0,25.0,0.0,68.0,155.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,26.0,0.0,64.0,136.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,26.0,32.0,0.0,64.0,140.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,39.0,66.0,0.0,65.0,140.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.mllib.feature as ft\n",
    "import pyspark.mllib.regression as reg\n",
    "\n",
    "hashing = ft.HashingTF(7)\n",
    "\n",
    "print(births_transformed.take(10))\n",
    "\n",
    "\n",
    "births_hashed = births_transformed \\\n",
    "    .rdd \\\n",
    "    .map(lambda row: [\n",
    "            list(hashing.transform(row[1]).toArray()) \n",
    "                if col == 'BIRTH_PLACE' \n",
    "                else row[i] \n",
    "            for i, col \n",
    "            in enumerate(features_to_keep)]) \\\n",
    "    .map(lambda row: [[e] if type(e) == int else e \n",
    "                      for e in row]) \\\n",
    "    .map(lambda row: [item for sublist in row \n",
    "                      for item in sublist]) \\\n",
    "    .map(lambda row: reg.LabeledPoint(\n",
    "            row[0], \n",
    "            ln.Vectors.dense(row[1:]))\n",
    "        )\n",
    "\n",
    "births_hashed.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습용과 테스트용으로 분할 \n",
    "6:4로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,29.0,99.0,0.0,99.0,999.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,39.0,42.0,0.0,60.0,128.0,0.0,0.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,18.0,99.0,4.0,61.0,110.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,32.0,37.0,0.0,66.0,150.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,26.0,0.0,64.0,136.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,33.0,99.0,0.0,65.0,145.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,29.0,99.0,0.0,60.0,115.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,31.0,41.0,0.0,59.0,106.0,0.0,0.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,27.0,99.0,0.0,66.0,213.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,34.0,31.0,0.0,70.0,130.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_train, births_test = births_hashed.randomSplit([0.6, 0.4])\n",
    "\n",
    "births_test.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification \\\n",
    "    import LogisticRegressionWithLBFGS\n",
    "\n",
    "LR_Model = LogisticRegressionWithLBFGS \\\n",
    "    .train(births_train, iterations=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델을 테스트셋을 이용해서 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = spark.sparkContext.parallelize(births_test.map(lambda row: row.label).map(lambda x: x * 1.0).collect())\n",
    "prediction = spark.sparkContext.parallelize(LR_Model.predict(births_test.map(lambda row: row.features)).map(lambda x: x * 1.0).collect())\n",
    "LR_results = truth.zip(prediction)\n",
    "LR_results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.80\n",
      "Area under ROC: 0.63\n"
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.evaluation as ev\n",
    "\n",
    "# import pyspark.mllib.evaluation as ev\n",
    "LR_evaluation = ev.BinaryClassificationMetrics(LR_results)\n",
    "\n",
    "print('Area under PR: {0:.2f}' \\\n",
    "      .format(LR_evaluation.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}' \\\n",
    "      .format(LR_evaluation.areaUnderROC))\n",
    "LR_evaluation.unpersist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셀렉터를 통해서 가장 좋은 피쳐를 뽑아냅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ft.ChiSqSelector(4).fit(births_train)\n",
    "\n",
    "\n",
    "train_label = spark.sparkContext.parallelize(births_train.map(lambda row: row.label).collect())\n",
    "selected_train_feature = spark.sparkContext.parallelize(selector.transform(births_train.map(lambda row: row.features)).collect())\n",
    "\n",
    "topFeatures_train = (train_label.zip(selected_train_feature)).map(lambda row: reg.LabeledPoint(row[0], row[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_label = spark.sparkContext.parallelize(births_test.map(lambda row: row.label).collect()) \n",
    "selected_test_feature = spark.sparkContext.parallelize(selector.transform(births_test.map(lambda row: row.features)).collect())\n",
    "\n",
    "\n",
    "topFeatures_test = test_label.zip(selected_test_feature).map(lambda row: reg.LabeledPoint(row[0], row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "\n",
    "RF_model = RandomForest \\\n",
    "    .trainClassifier(data=topFeatures_train, \n",
    "                     numClasses=2, \n",
    "                     categoricalFeaturesInfo={}, \n",
    "                     numTrees=6,  \n",
    "                     featureSubsetStrategy='all',\n",
    "                     seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feature_truth = spark.sparkContext.parallelize(topFeatures_test.map(lambda row: row.label).collect())\n",
    "top_feature_prediction = spark.sparkContext.parallelize(RF_model.predict(topFeatures_test.map(lambda row: row.features)).collect())\n",
    "\n",
    "RF_results = top_feature_truth.zip(top_feature_prediction)\n",
    "\n",
    "RF_results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.79\n",
      "Area under ROC: 0.62\n"
     ]
    }
   ],
   "source": [
    "RF_evaluation = ev.BinaryClassificationMetrics(RF_results)\n",
    "\n",
    "print('Area under PR: {0:.2f}' \\\n",
    "      .format(RF_evaluation.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}' \\\n",
    "      .format(RF_evaluation.areaUnderROC))\n",
    "RF_evaluation.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.83\n",
      "Area under ROC: 0.63\n"
     ]
    }
   ],
   "source": [
    "LR_Model_2 = LogisticRegressionWithLBFGS \\\n",
    "    .train(topFeatures_train, iterations=10)\n",
    "\n",
    "top_feature_truth = spark.sparkContext.parallelize(topFeatures_test.map(lambda row: row.label).map(lambda x: x * 1.0).collect())\n",
    "top_feature_prediction = spark.sparkContext.parallelize(LR_Model_2.predict(topFeatures_test.map(lambda row: row.features)).map(lambda x: x * 1.0).collect())\n",
    "LR_results_2 = top_feature_truth.zip(top_feature_prediction)\n",
    "\n",
    "LR_evaluation_2 = ev.BinaryClassificationMetrics(LR_results_2)\n",
    "\n",
    "print('Area under PR: {0:.2f}' \\\n",
    "      .format(LR_evaluation_2.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}' \\\n",
    "      .format(LR_evaluation_2.areaUnderROC))\n",
    "LR_evaluation_2.unpersist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
